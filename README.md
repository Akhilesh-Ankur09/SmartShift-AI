# ğŸ§  SmartShift-AI

**SmartShift-AI** is an AI-powered **Shift-End Reporting and Meeting Summarization System** built with **Python, FastAPI, Whisper**, and **NLP**.  
It automatically transcribes meeting recordings, generates structured summaries, and stores all reports for future access â€” making your workflow faster, smarter, and organized.

---

## ğŸš€ Features

- ğŸ™ **Speech-to-Text (OpenAI Whisper)** â€” Accurately transcribes meeting audio into text.  
- ğŸ§¾ **Automatic Report Generation** â€” NLP-based summarization of meeting discussions.  
- ğŸ•’ **Meeting Metadata** â€” Each report stores date, title, transcript, and summaries.  
- ğŸ—ƒ **Persistent Storage (SQLite)** â€” Saves meeting records for retrieval anytime.  
- âš™ï¸ **REST API with FastAPI** â€” Easy-to-use, interactive endpoints.  
- ğŸ“± **Future Integration** â€” Flutter frontend for dashboards and shift-end summaries.

---

## ğŸ§± Project Structure

SmartShift-AI/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ api/
â”‚ â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”‚ â””â”€â”€ schemas.py # Pydantic API models (request/response)
â”‚ â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â”‚ â””â”€â”€ transcription.py # All endpoints (transcribe, reports, summarize)
â”‚ â”‚ â””â”€â”€ crud.py # Database interaction functions
â”‚ â”‚
â”‚ â”œâ”€â”€ database/
â”‚ â”‚ â”œâ”€â”€ db.py # Database connection (SQLAlchemy + SQLite)
â”‚ â”‚ â””â”€â”€ models.py # SQLAlchemy models for DB tables
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/
â”‚ â”‚ â””â”€â”€ summarizer.py # NLP summarizer (Hugging Face - BART)
â”‚ â”‚
â”‚ â”œâ”€â”€ main.py # FastAPI app entry point
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â”‚
â”œâ”€â”€ .gitignore # Ignore build, venv, cache files
â””â”€â”€ README.md # Project documentation (this file)


---

## ğŸ§° Tech Stack

| Component | Technology |
|------------|-------------|
| **Backend** | FastAPI (Python) |
| **Speech Recognition** | OpenAI Whisper |
| **NLP Summarization** | Hugging Face Transformers (BART) |
| **Database** | SQLite (via SQLAlchemy ORM) |
| **Language** | Python 3.11 |
| **Frontend (Planned)** | Flutter |

---

## âš™ï¸ Installation & Setup (Step-by-Step)

> ğŸ§‘â€ğŸ’» Follow these steps carefully to set up your environment.

### ğŸªœ 1. Clone the Repository
```bash
git clone https://github.com/Akhilesh-Ankur09/SmartShift-AI.git
cd SmartShift-AI

ğŸªœ 2. Create and Activate Virtual Environment
```bash
python -m venv .venv
.venv\Scripts\activate   # For Windows
# OR
source .venv/bin/activate  # For Linux/Mac

ğŸªœ 3. Install Dependencies
```bash
cd backend
pip install -r requirements.txt

ğŸªœ 4. Run the FastAPI Server
```bash
uvicorn main:app --reload

âœ… Server will start at:
ğŸ‘‰ http://127.0.0.1:8000

âœ… Interactive API Docs:
ğŸ‘‰ http://127.0.0.1:8000/docs

ğŸªœ 5. Verify Setup
You should see logs like:

INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000


Then, open /docs to test your endpoints.

ğŸ§© API Endpoints
Endpoint	Method	Description
/api/transcribe	POST	Upload an audio/video file, transcribe with Whisper, and save to DB
/api/reports	GET	Retrieve all saved meeting reports
/api/summarize/{meeting_id}	POST	Generate a summary for a specific meeting by ID

ğŸ§  Example Workflow

1ï¸âƒ£ Upload a meeting recording

POST /api/transcribe


Upload .wav or .mp4 file

(Optional) Add a meeting title
âœ… Returns transcript preview and saves it to the database.

2ï¸âƒ£ List all reports

GET /api/reports


Shows all saved meetings with title, date, and transcript IDs.

3ï¸âƒ£ Generate a summary

POST /api/summarize/{meeting_id}


Replace {meeting_id} with the ID from /api/reports
âœ… Returns and saves the NLP-generated summary.

ğŸ—‚ Database Schema (MeetingReport Table)
Column	Type	Description
id	Integer (PK)	Unique report ID
meeting_title	String	Meeting name/title
meeting_date	DateTime	Date of meeting
started_at	DateTime	Meeting start time
ended_at	DateTime	Meeting end time
transcript_text	Text	Full meeting transcript
final_summary	Text	NLP-generated summary
raw_transcript_path	String	Path to raw audio file (optional)
ğŸ§± Example JSON Responses
ğŸ“© /api/transcribe
{
  "message": "Transcription saved successfully!",
  "meeting_id": 1,
  "meeting_title": "Daily Standup",
  "meeting_date": "2025-10-12T12:32:15.321Z",
  "transcript_preview": "Today the team discussed progress..."
}

ğŸ“¤ /api/reports
[
  {
    "id": 1,
    "meeting_title": "Daily Standup",
    "meeting_date": "2025-10-12T12:32:15.321Z",
    "final_summary": null
  }
]

ğŸ§¾ /api/summarize/1
{
  "meeting_id": 1,
  "meeting_title": "Daily Standup",
  "summary": "The team reviewed ongoing tasks, discussed blockers, and planned next steps."
}

ğŸ§­ Development Commands
Task	Command
Start server	uvicorn main:app --reload
Install deps	pip install -r requirements.txt
Freeze deps	pip freeze > requirements.txt
Run in prod (optional)	uvicorn main:app --host 0.0.0.0 --port 8080
ğŸ“ˆ Roadmap

 FastAPI + Whisper integration

 SQLite database with SQLAlchemy ORM

 NLP summarization (BART model)

 Interval-based meeting summaries

 Flutter dashboard integration

 Docker & Render deployment

 User authentication system

 Export reports to PDF/Email

ğŸ§‘â€ğŸ’» Author

Akhilesh Ankur
ğŸ“ MCA Graduate | AI & Automation Enthusiast
ğŸ“ India
ğŸ”— LinkedIn

ğŸ’» GitHub

ğŸªª License

This project is licensed under the MIT License â€” see the LICENSE
 file for details.

ğŸ¤ Contributing

Contributions are welcome!
Feel free to fork this repo, open issues, or create pull requests.

1. Fork the project
2. Create your feature branch (git checkout -b feature-name)
3. Commit your changes (git commit -m "Add feature-name")
4. Push to your branch (git push origin feature-name)
5. Open a Pull Request ğŸš€

ğŸŒŸ Acknowledgements

[OpenAI Whisper](https://github.com/openai/whisper)
 for robust speech recognition

[Hugging Face Transformers](https://huggingface.co/transformers/)
 for text summarization

[FastAPI](https://fastapi.tiangolo.com/)
 for modern Python APIs

[SQLite](https://sqlite.org/)
 for easy local data storage